# MovieLens Recommender: Addressing User Cold-Start Recommendation with LLM Data Augmentation

## Overview

This project tackles the well-known cold-start problem in recommendation systems by leveraging Large Language Models (LLMs) to generate synthetic user-item interactions. By augmenting limited user history with LLM-generated preferences, we aim to significantly improve recommendation quality for new (cold-start) users.


## Problem Statement

Traditional recommendation systems struggle with new users who have minimal interaction history, often leading to generic or suboptimal recommendations. This project demonstrates how LLM-generated synthetic data can bridge that gap, providing more accurate and personalized recommendations.


## Data Sources

- **MovieLens 100K Dataset:** Contains 100,000 ratings from 943 users on 1,682 movies.
- **MovieLens 1M Dataset:** Contains 1 million ratings from 6,040 users on 3,900 movies.

**Download Links:**
- [MovieLens 100K](https://grouplens.org/datasets/movielens/100k/)
- [MovieLens 1M](https://grouplens.org/datasets/movielens/1m/)

> **Setup:** Ensure you download and extract the datasets into the `data/` directory.


## Methodology

### 1. Data Processing
- **ID Mapping:** The code processes the MovieLens datasets with efficient mapping of user and item IDs.
- **Formatting:** Raw ratings are transformed into structured formats suitable for both collaborative filtering and neural recommendation models.

### 2. Cold-Start Simulation
- **User Sampling:** Approximately 20% of users are designated as "cold users." Their interaction history is artificially reduced to just one item (to maintain functionality for sequential models like SASRec).
- **Purpose:** This simulation allows for the evaluation of the impact of LLM-based data augmentation on recommendation quality.

### 3. LLM Data Augmentation
- **Model & Prompting:** 
  - Uses LLaMA-3B (or similar models such as `meta-llama/Llama-3.2-3B-Instruct`) with pairwise prompting techniques.
  - **Prompt Example:**  
    > "Suppose you were a 30-year-old male programmer with a history of low ratings for a Comedy movie. Which movie would you prefer between *Psycho II (1983)* (Horror/Thriller) and *Ben-Hur (1959)* (Action/Adventure)? Answer 1 for the first movie or 2 for the second movie. The only valid outputs are the integers 1 or 2."
- **Integration:** Synthetic user-item interactions generated by the LLM are merged with real user interactions to enrich the training dataset.

### 4. Model Implementation
- **Two-Tower Matrix Factorization:**  
  Learns separate user and item embeddings via dual neural networks.
- **Sequential Recommendation (SASRec):**  
  Employs an attention mechanism to predict the next interaction based on the user's history.
- **Evaluation:**  
  Uses negative sampling ("Leave-One-Out") and ranking metrics such as Hit Rate (HR@K) and Normalized Discounted Cumulative Gain (NDCG@K).


## Code Structure

- **TensorFlow & TensorFlow Recommenders:**  
  Core frameworks for building recommendation models.
- **UserModel & ItemModel:**  
  Separate embedding towers in the two-tower architecture.
- **TwoTowerModel:**  
  Combines user and item embeddings for retrieval-based recommendations.
- **Evaluation Functions:**  
  Implements both negative sampling and standard RecSys metrics.


## Experimental Setup & Results

### Baseline & Augmentation Comparison

Two sets of experiments were conducted:

1. **Baseline:**  
   - Cold users have only one real interaction.
   - Models: Matrix Factorization (MF) and SASRec.

2. **LLM-Augmented:**  
   - Synthetic interactions (generated via pairwise prompting) are added to cold users’ histories.
   - **Key Metrics:**  
     - **Hit Rate (HR@K)**
     - **Normalized Discounted Cumulative Gain (NDCG@K)**

**Findings:**
- **Matrix Factorization:**  
  Significant improvements were observed with LLM augmentation—up to a 31% increase in NDCG@K and a 43% boost in HR@K on the ML-100K dataset.
- **SASRec:**  
  While SASRec maintained strong performance overall, the augmented cold users’ interactions produced mixed results, suggesting that sequential models may require more refined prompting (e.g., using in-context examples) to better leverage synthetic data.



## Expected Results

- **Improved Recommendations:**  
  Enhanced recommendation quality for cold-start users, particularly when using LLM-augmented interactions.
- **Insights on Prompting:**  
  Analysis indicates that the format and content of the prompt (e.g., including in-context examples) can further influence performance.
- **Model Comparison:**  
  While MF shows clear gains from augmentation, sequential models like SASRec require further tuning to optimally integrate augmented data.


## Future Directions

- **Extended Augmentation:**  
  Experiment with injecting 2–3 synthetic interactions per cold user.
- **Prompting Strategies:**  
  Evaluate different prompting schemes (pairwise, pointwise, three-wise) and incorporate in-context training examples.
- **Separate Metrics:**  
  Compute evaluation metrics distinctly for cold and warm users to better isolate the effects of augmentation.
- **Alternative Datasets:**  
  Consider applying the method to datasets with naturally occurring cold users, such as Amazon Product Reviews.
- **Larger LLMs:**  
  Explore using larger models (e.g., LLaMA-8B) to assess their impact on data augmentation quality.


## Team

- **Nachiket Subbaraman**
- **Georgy Zaets**
- **Anant Vishwakarma**
- **Zeerak Babar**
- **Jaskinder Sarai**

**Contact:**  
[nsubbaraman, gzaets, abvishwakarma, zebabar, jssarai]@ucdavis.edu


## Repository

For complete code, data processing scripts, and experiment details, please visit the [Project Repository](https://github.com/gzaets/movielens_recommender).


## References

Key references used in the project include:
- Collaborative Filtering and Matrix Factorization literature.
- Recent studies on LLM integration in recommendation systems (e.g., LLaMa4Rec).
- Benchmark models such as SASRec and related papers on self-attentive sequential recommendation.

